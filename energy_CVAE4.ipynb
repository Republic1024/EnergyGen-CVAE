{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 电力负荷数据合成：解锁电网分析新可能\n",
    "\n",
    "在现代电力系统中，数据是驱动洞察和优化的核心。然而，获取、管理和共享真实电力负荷数据常常面临隐私、成本和数据稀疏性等挑战。**电力负荷数据合成**提供了一个强大的解决方案，它利用先进的机器学习技术来生成与真实数据统计特性相似的**人造数据**。这不仅能有效弥补数据不足，还能在保护隐私的前提下，为电网的分析、预测、优化及算法测试提供丰富、多样化的数据支持。\n",
    "\n",
    "### 为何合成电力负荷数据如此重要？\n",
    "\n",
    "* **隐私保护与合规性：** 真实的电力数据往往包含敏感的用户行为信息。合成数据允许在不暴露原始数据的情况下进行分析和共享，满足严格的数据隐私法规要求。\n",
    "* **弥补数据不足：** 面对传感器故障、通信中断或特定历史数据缺失时，合成数据能够填补空白，构建更完整、连续的数据集。\n",
    "* **数据增强与多样化：** 通过生成不同条件（如极端天气、突发事件）下的数据，我们可以扩充现有数据集，提高模型的泛化能力和鲁棒性，让算法在更广泛的场景下表现出色。\n",
    "* **算法测试与开发：** 无论是新的负荷预测模型还是需求响应策略，都需要大量数据进行训练和验证。合成数据提供了一个安全、可控的环境，加速算法的迭代和优化。\n",
    "* **降低成本：** 相较于真实数据的采集、清洗和存储，合成数据显著降低了数据获取的成本和复杂度。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e80ede8073c6326"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![research_overview](4ee8a7ae1a3c096a9b72318594b2b13.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b92dcf199d2a447"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "### 核心合成模型与方法\n",
    "\n",
    "电力负荷数据合成主要依赖于**深度生成模型**，这些模型擅长学习复杂数据的高维分布并生成逼真样本。\n",
    "\n",
    "#### 1. 条件变分自编码器 (CVAE)\n",
    "\n",
    "我们此次实现的核心模型就是 **CVAE**。\n",
    "\n",
    "* **工作原理：** CVAE 能够学习在给定**条件信息**（例如：温度、湿度、风速、日期和时间等环境与时序特征）时，电力负荷数据（`PowerConsumption_Zone1, Zone2, Zone3`）的分布。它将输入数据编码成一个**潜在空间**中的概率分布，再由解码器结合条件信息从该潜在空间中采样并重建数据。\n",
    "* **优势：** CVAE 能够生成具有多样性的数据，并且最关键的是，它允许我们**控制生成过程**，根据特定的环境和时间条件来定制合成的电力负荷数据，这对于模拟特定场景下的电力行为至关重要。\n",
    "\n",
    "#### 2. 生成对抗网络 (GANs)\n",
    "\n",
    "* **工作原理：** GANs 由一个**生成器**和一个**判别器**组成。生成器负责创造看起来真实的合成数据，而判别器则努力区分真实数据和生成数据。两者在对抗中不断提升，最终生成器能够产生高度逼真的数据。\n",
    "* **优势：** 在生成视觉上极度逼真的数据方面表现卓越，也能应用于时序数据。\n",
    "\n",
    "#### 3. 扩散模型 (Diffusion Models)\n",
    "\n",
    "* **工作原理：** 这类模型通过模拟一个逐步添加噪声的“前向扩散”过程，然后学习逆向的“去噪”过程来生成数据。\n",
    "* **优势：** 近年来在图像和音频生成领域取得了突破性进展，能够生成高质量、细节丰富的样本，在复杂数据分布建模方面潜力巨大，是未来在电力数据合成领域值得探索的方向。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa4e4a95e8c8720e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![what_we_do](cvae_architecture_diagram.svg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "186f3e3e51c5f0bf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "--- 数据维度检查 ---\n",
      "训练集-连续条件: torch.Size([41932, 5])\n",
      "训练集-类别条件: torch.Size([41932, 3])\n",
      "训练集-目标: torch.Size([41932, 3])\n",
      "测试集-连续条件: torch.Size([10484, 5])\n",
      "测试集-类别条件: torch.Size([10484, 3])\n",
      "测试集-目标: torch.Size([10484, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# --- 环境设置 ---\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['font.sans-serif'] = ['Misans']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# --- 读取和预处理数据 ---\n",
    "df = pd.read_csv(\"./data/powerconsumption.csv\")\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "\n",
    "# 提取时间特征 (作为类别特征)\n",
    "df['Hour'] = df['Datetime'].dt.hour\n",
    "df['DayOfWeek'] = df['Datetime'].dt.dayofweek\n",
    "df['Month'] = df['Datetime'].dt.month - 1\n",
    "\n",
    "# 定义连续条件特征、类别条件特征和目标特征\n",
    "continuous_conditional_features = ['Temperature', 'Humidity', 'WindSpeed', 'GeneralDiffuseFlows', 'DiffuseFlows']\n",
    "categorical_conditional_features = ['Hour', 'DayOfWeek', 'Month']\n",
    "target_features = ['PowerConsumption_Zone1', 'PowerConsumption_Zone2', 'PowerConsumption_Zone3']\n",
    "\n",
    "# 划分训练集和测试集 (80/20)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_df, test_df = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# 对连续特征和目标特征进行归一化\n",
    "scaler_cond_continuous = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "# 训练集缩放\n",
    "train_df[continuous_conditional_features] = scaler_cond_continuous.fit_transform(\n",
    "    train_df[continuous_conditional_features])\n",
    "train_df[target_features] = scaler_target.fit_transform(train_df[target_features])\n",
    "\n",
    "# 测试集缩放\n",
    "test_df[continuous_conditional_features] = scaler_cond_continuous.transform(test_df[continuous_conditional_features])\n",
    "test_df[target_features] = scaler_target.transform(test_df[target_features])\n",
    "\n",
    "# 准备 Tensors\n",
    "# 训练数据\n",
    "X_train_cont = torch.tensor(train_df[continuous_conditional_features].values, dtype=torch.float32)\n",
    "X_train_cat = torch.tensor(train_df[categorical_conditional_features].values, dtype=torch.long)\n",
    "y_train = torch.tensor(train_df[target_features].values, dtype=torch.float32)\n",
    "\n",
    "# 测试数据\n",
    "X_test_cont = torch.tensor(test_df[continuous_conditional_features].values, dtype=torch.float32)\n",
    "X_test_cat = torch.tensor(test_df[categorical_conditional_features].values, dtype=torch.long)\n",
    "y_test = torch.tensor(test_df[target_features].values, dtype=torch.float32)\n",
    "\n",
    "# 创建 DataLoader\n",
    "batch_size = 256\n",
    "train_dataset = TensorDataset(X_train_cont, X_train_cat, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_cont, X_test_cat, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"--- 数据维度检查 ---\")\n",
    "print(f\"训练集-连续条件: {X_train_cont.shape}\")\n",
    "print(f\"训练集-类别条件: {X_train_cat.shape}\")\n",
    "print(f\"训练集-目标: {y_train.shape}\")\n",
    "print(f\"测试集-连续条件: {X_test_cont.shape}\")\n",
    "print(f\"测试集-类别条件: {X_test_cat.shape}\")\n",
    "print(f\"测试集-目标: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-13T14:58:36.239006400Z",
     "start_time": "2025-07-13T14:58:30.867869300Z"
    }
   },
   "id": "ee3886bb1ecf669f",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "![the_priciple_of_generation](34488b69a3202d7dc6a3631b30d3a6e.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "563ab1cf5e5fa065"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class UpgradedCVAE(nn.Module):\n",
    "    def __init__(self, target_dim, cont_cond_dim, latent_dim,\n",
    "                 cat_dims, embedding_dims):\n",
    "        super(UpgradedCVAE, self).__init__()\n",
    "\n",
    "        self.target_dim = target_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 1. 条件特征嵌入层\n",
    "        self.hour_embed = nn.Embedding(cat_dims['Hour'], embedding_dims['Hour'])\n",
    "        self.day_embed = nn.Embedding(cat_dims['DayOfWeek'], embedding_dims['DayOfWeek'])\n",
    "        self.month_embed = nn.Embedding(cat_dims['Month'], embedding_dims['Month'])\n",
    "\n",
    "        total_embedding_dim = embedding_dims['Hour'] + embedding_dims['DayOfWeek'] + embedding_dims['Month']\n",
    "        conditional_dim = cont_cond_dim + total_embedding_dim\n",
    "\n",
    "        # 2. 编码器 (Encoder)\n",
    "        encoder_input_dim = target_dim + conditional_dim\n",
    "        self.encoder_net = nn.Sequential(\n",
    "            nn.Linear(encoder_input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(128, latent_dim)\n",
    "\n",
    "        # 3. 解码器 (Decoder) - 多任务结构\n",
    "        decoder_input_dim = latent_dim + conditional_dim\n",
    "        self.decoder_shared = nn.Sequential(\n",
    "            nn.Linear(decoder_input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 为每个Zone创建独立的输出头\n",
    "        self.decoder_zone1 = nn.Linear(256, 1)\n",
    "        self.decoder_zone2 = nn.Linear(256, 1)\n",
    "        self.decoder_zone3 = nn.Linear(256, 1)\n",
    "\n",
    "    def process_conditions(self, c_cont, c_cat):\n",
    "        # c_cat shape: (batch_size, num_cat_features)\n",
    "        hour_emb = self.hour_embed(c_cat[:, 0])\n",
    "        day_emb = self.day_embed(c_cat[:, 1])\n",
    "        month_emb = self.month_embed(c_cat[:, 2])\n",
    "\n",
    "        c_emb = torch.cat([hour_emb, day_emb, month_emb], dim=1)\n",
    "        c_combined = torch.cat([c_cont, c_emb], dim=1)\n",
    "        return c_combined\n",
    "\n",
    "    def encode(self, x, c_cont, c_cat):\n",
    "        c = self.process_conditions(c_cont, c_cat)\n",
    "        inputs = torch.cat([x, c], dim=1)\n",
    "        h = self.encoder_net(inputs)\n",
    "        return self.fc_mu(h), self.fc_log_var(h)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, c_cont, c_cat):\n",
    "        c = self.process_conditions(c_cont, c_cat)\n",
    "        inputs = torch.cat([z, c], dim=1)\n",
    "\n",
    "        h_shared = self.decoder_shared(inputs)\n",
    "\n",
    "        out1 = self.decoder_zone1(h_shared)\n",
    "        out2 = self.decoder_zone2(h_shared)\n",
    "        out3 = self.decoder_zone3(h_shared)\n",
    "\n",
    "        # 将三个Zone的输出拼接起来，并用Sigmoid确保范围在[0,1]\n",
    "        return torch.sigmoid(torch.cat([out1, out2, out3], dim=1))\n",
    "\n",
    "    def forward(self, x, c_cont, c_cat):\n",
    "        mu, log_var = self.encode(x, c_cont, c_cat)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction = self.decode(z, c_cont, c_cat)\n",
    "        return reconstruction, mu, log_var\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, c_cont, c_cat):\n",
    "        z = torch.randn(c_cont.size(0), self.latent_dim, device=c_cont.device)\n",
    "        return self.decode(z, c_cont, c_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-13T14:58:36.240005800Z",
     "start_time": "2025-07-13T14:58:34.970348800Z"
    }
   },
   "id": "b629d06805b02685",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mmd_loss(p, q, kernel='rbf', sigma=1.0):\n",
    "    \"\"\"计算p和q两个batch之间的MMD损失\"\"\"\n",
    "    # p: 真实样本 (batch_size, dim)\n",
    "    # q: 生成样本 (batch_size, dim)\n",
    "    xx, yy, zz = torch.mm(p, p.t()), torch.mm(q, q.t()), torch.mm(p, q.t())\n",
    "\n",
    "    # RBF 核 (高斯核)\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    Kxx = torch.exp(-0.5 * (rx.t() + rx - 2 * xx) / sigma ** 2)\n",
    "    Kyy = torch.exp(-0.5 * (ry.t() + ry - 2 * yy) / sigma ** 2)\n",
    "    Kxy = torch.exp(-0.5 * (rx.t() + ry - 2 * zz) / sigma ** 2)\n",
    "\n",
    "    return Kxx.mean() + Kyy.mean() - 2 * Kxy.mean()\n",
    "\n",
    "\n",
    "def combined_loss_function(recon_x, x, mu, log_var, generated_x,\n",
    "                           zone_weights, beta=1.0, alpha=1.0):\n",
    "    \"\"\"\n",
    "    计算总损失 = 加权重建损失 + beta * KLD + alpha * MMD\n",
    "    \"\"\"\n",
    "    # 1. 加权重建损失 (Weighted MSE)\n",
    "    recon_loss_per_zone = torch.mean((recon_x - x) ** 2, dim=0)  # 按Zone计算MSE\n",
    "    weighted_recon_loss = torch.sum(recon_loss_per_zone * zone_weights)\n",
    "\n",
    "    # 2. KL 散度损失\n",
    "    kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    kld_loss /= x.size(0)  # 平均到每个样本\n",
    "\n",
    "    # 3. MMD 损失\n",
    "    mmd = mmd_loss(x, generated_x)\n",
    "\n",
    "    # 4. 组合损失\n",
    "    total_loss = weighted_recon_loss + beta * kld_loss + alpha * mmd\n",
    "\n",
    "    return total_loss, weighted_recon_loss, kld_loss, mmd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-13T14:58:36.291668500Z",
     "start_time": "2025-07-13T14:58:34.980350Z"
    }
   },
   "id": "2c6bd2433c1510a1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from tqdm.notebook import tqdm\n",
    "# ... your existing code ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-13T14:58:36.292668900Z",
     "start_time": "2025-07-13T14:58:34.995347900Z"
    }
   },
   "id": "39aa1f191bee10ce",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- 模型超参数 ---\n",
    "TARGET_DIM = y_train.shape[1]\n",
    "CONT_COND_DIM = X_train_cont.shape[1]\n",
    "LATENT_DIM = 30\n",
    "CAT_DIMS = {'Hour': 24, 'DayOfWeek': 7, 'Month': 12}\n",
    "EMBEDDING_DIMS = {'Hour': 8, 'DayOfWeek': 4, 'Month': 4}\n",
    "\n",
    "# # --- 训练超参数:old ---\n",
    "# EPOCHS = 100\n",
    "# LEARNING_RATE = 1e-4\n",
    "# BETA = 0.1  # KLD损失的权重 (可调)\n",
    "# ALPHA = 10.0  # MMD损失的权重 (可调)\n",
    "# # 为Zone3赋予更高权重\n",
    "# ZONE_WEIGHTS = torch.tensor([1.0, 1.0, 3.0]).to(device)\n",
    "\n",
    "# --- 训练超参数 ---\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "BETA = 0.05  # KLD损失的权重 (可调)\n",
    "ALPHA = 10.0  # MMD损失的权重 (可调)\n",
    "# 为Zone3赋予更高权重\n",
    "ZONE_WEIGHTS = torch.tensor([1.0, 1.0, 0.5]).to(device)\n",
    "\n",
    "# --- 初始化 ---\n",
    "model = UpgradedCVAE(\n",
    "    target_dim=TARGET_DIM,\n",
    "    cont_cond_dim=CONT_COND_DIM,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    cat_dims=CAT_DIMS,\n",
    "    embedding_dims=EMBEDDING_DIMS\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 训练与评估循环 ---\n",
    "train_losses, test_mses = [], []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    total_loss, total_recon, total_kld, total_mmd = 0, 0, 0, 0\n",
    "\n",
    "    # 使用tqdm进行训练可视化\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\", unit=\"batch\")\n",
    "\n",
    "    for c_cont, c_cat, x in pbar:\n",
    "        c_cont, c_cat, x = c_cont.to(device), c_cat.to(device), x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        recon_x, mu, log_var = model(x, c_cont, c_cat)\n",
    "\n",
    "        # 为MMD损失生成样本\n",
    "        generated_x = model.generate(c_cont, c_cat)\n",
    "\n",
    "        # 计算损失\n",
    "        loss, recon, kld, mmd = combined_loss_function(\n",
    "            recon_x, x, mu, log_var, generated_x, ZONE_WEIGHTS, BETA, ALPHA\n",
    "        )\n",
    "\n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_recon += recon.item()\n",
    "        total_kld += kld.item()\n",
    "        total_mmd += mmd.item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Recon': f'{recon.item():.4f}',\n",
    "            'KLD': f'{kld.item():.4f}',\n",
    "            'MMD': f'{mmd.item():.4f}'\n",
    "        })\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_recon = total_recon / len(train_loader)\n",
    "    avg_kld = total_kld / len(train_loader)\n",
    "    avg_mmd = total_mmd / len(train_loader)\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} Avg Train Loss: {avg_loss:.4f} | Recon: {avg_recon:.4f} | KLD: {avg_kld:.4f} | MMD: {avg_mmd:.4f}\")\n",
    "\n",
    "    # --- 在测试集上评估 ---\n",
    "    model.eval()\n",
    "    all_recon_x = []\n",
    "    all_x = []\n",
    "    with torch.no_grad():\n",
    "        for c_cont, c_cat, x in test_loader:\n",
    "            c_cont, c_cat, x = c_cont.to(device), c_cat.to(device), x.to(device)\n",
    "            recon_x, _, _ = model(x, c_cont, c_cat)\n",
    "            all_recon_x.append(recon_x)\n",
    "            all_x.append(x)\n",
    "\n",
    "    all_recon_x = torch.cat(all_recon_x, dim=0)\n",
    "    all_x = torch.cat(all_x, dim=0)\n",
    "\n",
    "    # 计算每个Zone的MSE\n",
    "    test_mse = torch.mean((all_recon_x - all_x) ** 2, dim=0)\n",
    "    test_mses.append(test_mse.cpu().numpy())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Test MSE -> \"\n",
    "          f\"Zone1: {test_mse[0]:.6f}, \"\n",
    "          f\"Zone2: {test_mse[1]:.6f}, \"\n",
    "          f\"Zone3: {test_mse[2]:.6f} (Weighted)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"训练完成!\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-07-13T14:58:35.016347500Z"
    }
   },
   "id": "7ebfc7ba0780e4cf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- 结果可视化 ---\n",
    "test_mses_np = np.array(test_mses)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_mses_np[:, 0], label='Zone 1 MSE')\n",
    "plt.plot(test_mses_np[:, 1], label='Zone 2 MSE')\n",
    "plt.plot(test_mses_np[:, 2], label='Zone 3 MSE (Weighted)', linestyle='--')\n",
    "plt.title('各区域在测试集上的MSE随Epoch变化')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "63070c51d577a012",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- 预测和真实对比可视化 ---\n",
    "model.eval()\n",
    "all_recon_x_unscaled = []\n",
    "all_x_unscaled = []\n",
    "all_c_cont_test = []\n",
    "all_c_cat_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c_cont, c_cat, x in test_loader:\n",
    "        c_cont, c_cat, x = c_cont.to(device), c_cat.to(device), x.to(device)\n",
    "        recon_x, _, _ = model(x, c_cont, c_cat)\n",
    "\n",
    "        # 将预测和真实值从GPU移回CPU并存储\n",
    "        all_recon_x_unscaled.append(recon_x.cpu().numpy())\n",
    "        all_x_unscaled.append(x.cpu().numpy())\n",
    "        all_c_cont_test.append(c_cont.cpu().numpy())\n",
    "        all_c_cat_test.append(c_cat.cpu().numpy())\n",
    "\n",
    "# 将所有批次的预测和真实值拼接起来\n",
    "all_recon_x_unscaled = np.concatenate(all_recon_x_unscaled, axis=0)\n",
    "all_x_unscaled = np.concatenate(all_x_unscaled, axis=0)\n",
    "\n",
    "# 使用 MinMax scaler 反转缩放\n",
    "all_recon_x_unscaled = scaler_target.inverse_transform(all_recon_x_unscaled)\n",
    "all_x_unscaled = scaler_target.inverse_transform(all_x_unscaled)\n",
    "\n",
    "# 选择前1000个点进行可视化\n",
    "num_points_to_plot = 24 * 6 * 10\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "for i, zone in enumerate(target_features):\n",
    "    plt.subplot(len(target_features), 1, i + 1)\n",
    "    plt.plot(all_x_unscaled[:num_points_to_plot, i], label=f'实际 {zone}', color='blue', alpha=0.7)\n",
    "    plt.plot(all_recon_x_unscaled[:num_points_to_plot, i], label=f'预测 {zone}', color='red', linestyle='--', alpha=0.7)\n",
    "    plt.title(f'测试集前{num_points_to_plot}个点：{zone} 预测 vs 实际')\n",
    "    plt.xlabel('时间点')\n",
    "    plt.ylabel('电量消耗')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8709e469e4a00a3d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- 预测和真实对比可视化与置信区间 ---\n",
    "model.eval()\n",
    "\n",
    "# 获取测试集数据\n",
    "# We will use the first batch or a selected subset of the test set for visualization\n",
    "# For simplicity, let's take the first 'num_points_to_plot' data points directly from tensors\n",
    "# Make sure these are on the correct device\n",
    "X_test_cont_plot = X_test_cont[:num_points_to_plot].to(device)\n",
    "X_test_cat_plot = X_test_cat[:num_points_to_plot].to(device)\n",
    "y_test_plot = y_test[:num_points_to_plot].to(device)\n",
    "\n",
    "num_samples_for_ci = 1000  # Number of samples to generate for each test point to build the CI\n",
    "\n",
    "# Store multiple predictions for each test point\n",
    "# Shape: (num_points_to_plot, num_samples_for_ci, target_dim)\n",
    "all_generated_samples_scaled = torch.zeros(\n",
    "    num_points_to_plot, num_samples_for_ci, TARGET_DIM\n",
    ").to(device)\n",
    "\n",
    "print(f\"Generating {num_samples_for_ci} samples for each of the first {num_points_to_plot} test points...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for s in tqdm(range(num_samples_for_ci), desc=\"Sampling for CI\"):\n",
    "        # For each sample, we pass the same conditional inputs to the model's generate method\n",
    "        # This will produce different outputs due to the reparameterization trick / sampling from Z\n",
    "        generated_s_scaled = model.generate(X_test_cont_plot, X_test_cat_plot)\n",
    "        all_generated_samples_scaled[:, s, :] = generated_s_scaled\n",
    "\n",
    "# Move to CPU and convert to NumPy\n",
    "all_generated_samples_scaled_np = all_generated_samples_scaled.cpu().numpy()\n",
    "y_test_plot_np = y_test_plot.cpu().numpy()\n",
    "\n",
    "# Inverse transform everything to original scale\n",
    "# (num_points_to_plot, num_samples_for_ci, target_dim)\n",
    "all_generated_samples_unscaled = np.array([\n",
    "    scaler_target.inverse_transform(all_generated_samples_scaled_np[i, :, :])\n",
    "    for i in range(num_points_to_plot)\n",
    "])\n",
    "\n",
    "# Inverse transform the actual test values\n",
    "y_test_plot_unscaled = scaler_target.inverse_transform(y_test_plot_np)\n",
    "\n",
    "# Calculate the mean prediction and confidence intervals (e.g., 95%)\n",
    "mean_predictions = np.mean(all_generated_samples_unscaled, axis=1)  # Shape: (num_points_to_plot, target_dim)\n",
    "lower_bound = np.percentile(all_generated_samples_unscaled, 2.5, axis=1)  # 2.5th percentile\n",
    "upper_bound = np.percentile(all_generated_samples_unscaled, 97.5, axis=1)  # 97.5th percentile\n",
    "\n",
    "# --- 可视化 ---\n",
    "num_points_to_plot_vis = 24 * 7 * 5  # Let's plot 2 weeks for clearer visualization of CI\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "for i, zone in enumerate(target_features):\n",
    "    plt.subplot(len(target_features), 1, i + 1)\n",
    "    plt.plot(y_test_plot_unscaled[:num_points_to_plot_vis, i], label=f'实际 {zone}', color='blue', alpha=0.8)\n",
    "    plt.plot(mean_predictions[:num_points_to_plot_vis, i], label=f'预测均值 {zone}', color='red', linestyle='-',\n",
    "             alpha=0.8)\n",
    "    plt.fill_between(\n",
    "        range(num_points_to_plot_vis),\n",
    "        lower_bound[:num_points_to_plot_vis, i],\n",
    "        upper_bound[:num_points_to_plot_vis, i],\n",
    "        color='red', alpha=0.2, label='95% 置信区间'\n",
    "    )\n",
    "    plt.title(f'测试集前{num_points_to_plot_vis}个点：{zone} 预测均值与95%置信区间 vs 实际')\n",
    "    plt.xlabel('时间点')\n",
    "    plt.ylabel('电量消耗')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7197e3495539fb9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 4))\n",
    "# for i, zone in enumerate(target_features):\n",
    "#     plt.subplot(1, len(target_features), i + 1)\n",
    "#     sns.kdeplot(all_x_unscaled[:, i], label=f'实际 {zone}', color='blue', fill=True, alpha=0.6)\n",
    "#     sns.kdeplot(all_recon_x_unscaled[:, i], label=f'预测 {zone}', color='red', linestyle='--', fill=True, alpha=0.4)\n",
    "#     plt.title(f'{zone} 预测 vs 实际分布')\n",
    "#     plt.xlabel('电量消耗')\n",
    "#     plt.ylabel('密度')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "94cbde5983f5ec23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_power_consumption(input_data):\n",
    "    \"\"\"\n",
    "    根据提供的环境和时间条件，生成 Zone 1、2 和 3 的合成电力消耗数据。\n",
    "\n",
    "    参数:\n",
    "        input_data (pd.Series 或 dict): 包含输入条件的一行数据，\n",
    "                                        键名需与原始数据列名匹配：\n",
    "                                        'Datetime', 'Temperature', 'Humidity',\n",
    "                                        'WindSpeed', 'GeneralDiffuseFlows', 'DiffuseFlows'。\n",
    "\n",
    "    返回:\n",
    "        dict: 包含生成的 'PowerConsumption_Zone1'、\n",
    "              'PowerConsumption_Zone2' 和 'PowerConsumption_Zone3' 的字典。\n",
    "    \"\"\"\n",
    "    # 1. 将 input_data 转换为 DataFrame 以进行统一处理\n",
    "    if isinstance(input_data, dict):\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "    elif isinstance(input_data, pd.Series):\n",
    "        input_df = pd.DataFrame([input_data.to_dict()])\n",
    "    else:\n",
    "        raise ValueError(\"input_data 必须是 pandas Series 或 dictionary 类型。\")\n",
    "\n",
    "    # 确保 'Datetime' 列是日期时间格式\n",
    "    input_df['Datetime'] = pd.to_datetime(input_df['Datetime'])\n",
    "\n",
    "    # 2. 提取时间特征 (与训练数据预处理保持一致)\n",
    "    input_df['Hour'] = input_df['Datetime'].dt.hour\n",
    "    input_df['DayOfWeek'] = input_df['Datetime'].dt.dayofweek\n",
    "    input_df['Month'] = input_df['Datetime'].dt.month  # Keep as 1-12 for encoding\n",
    "\n",
    "    # 3. 准备连续条件特征和类别条件特征 (不进行独热编码，而是直接送入模型的 Embedding 层)\n",
    "    # 提取连续条件特征\n",
    "    c_cont_input = input_df[continuous_conditional_features].values.astype(np.float32)\n",
    "\n",
    "    # 提取类别条件特征\n",
    "    # IMPORTANT: These should be the raw integer categorical values,\n",
    "    # as your UpgradedCVAE model takes `c_cat` as a `torch.long` tensor\n",
    "    # where each column is an index for an embedding.\n",
    "    # If your original training adjusted month to 0-11, this needs to be consistent here.\n",
    "    # Assuming `Month` is 1-12 from input_df and `CAT_DIMS` handles it.\n",
    "    # If `Month` was `month-1` in training, then it should be `input_df['Month'] - 1` here.\n",
    "    c_cat_input = input_df[categorical_conditional_features].values.astype(np.int64)\n",
    "\n",
    "    # 4. 使用预先拟合的 scaler_cond_continuous 对连续输入特征进行归一化\n",
    "    c_cont_scaled = scaler_cond_continuous.transform(c_cont_input)\n",
    "\n",
    "    # 将 NumPy 数组转换为 PyTorch 张量并移动到指定设备 (CPU/GPU)\n",
    "    c_cont_tensor = torch.tensor(c_cont_scaled, dtype=torch.float32).to(device)\n",
    "    c_cat_tensor = torch.tensor(c_cat_input, dtype=torch.long).to(device)\n",
    "\n",
    "    # 5. 使用训练好的 CVAE 模型生成合成数据\n",
    "    model.eval()  # 将模型设置为评估模式 (不计算梯度，不进行 dropout 等)\n",
    "    with torch.no_grad():  # 禁用梯度计算，节省内存并加速推理\n",
    "        # 生成样本，CVAE的generate方法只需要条件特征\n",
    "        generated_y_scaled = model.generate(c_cont_tensor, c_cat_tensor).cpu().numpy()\n",
    "\n",
    "    # 6. 将生成的归一化数据反归一化回原始尺度\n",
    "    generated_y_unscaled = scaler_target.inverse_transform(generated_y_scaled)\n",
    "\n",
    "    # 7. 格式化输出为字典\n",
    "    output_dict = {\n",
    "        'PowerConsumption_Zone1': generated_y_unscaled[0, 0],\n",
    "        'PowerConsumption_Zone2': generated_y_unscaled[0, 1],\n",
    "        'PowerConsumption_Zone3': generated_y_unscaled[0, 2]\n",
    "    }\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "# --- 示例用法 ---\n",
    "# 确保您的 'model'、'scaler_cond_continuous'、'scaler_target'、'LATENT_DIM'、'device'\n",
    "# 这些变量已经通过之前的训练步骤准备好并可用。\n",
    "# 上面我已经为这些变量提供了模拟的定义，以便此代码块可以直接运行。\n",
    "\n",
    "print(\"--- 运行生成函数示例 ---\")\n",
    "\n",
    "# 示例输入数据 1 (字典形式)\n",
    "example_input_data = {\n",
    "    'Datetime': '2017-01-01 00:00:00',\n",
    "    'Temperature': 6.559,\n",
    "    'Humidity': 73.8,\n",
    "    'WindSpeed': 0.083,\n",
    "    'GeneralDiffuseFlows': 0.051,\n",
    "    'DiffuseFlows': 0.119\n",
    "}\n",
    "\n",
    "generated_power = generate_power_consumption(example_input_data)\n",
    "print(\"\\n生成的电力消耗 (示例 1 - 新年午夜):\")\n",
    "for zone, value in generated_power.items():\n",
    "    print(f\"  {zone}: {value:.2f}\")\n",
    "\n",
    "# 示例输入数据 2 (夏季下午，潜在用电高峰)\n",
    "example_input_data_2 = {\n",
    "    'Datetime': '2017-07-15 14:30:00',  # 夏季下午\n",
    "    'Temperature': 35.0,\n",
    "    'Humidity': 60.0,\n",
    "    'WindSpeed': 2.5,\n",
    "    'GeneralDiffuseFlows': 800.0,\n",
    "    'DiffuseFlows': 250.0\n",
    "}\n",
    "generated_power_2 = generate_power_consumption(example_input_data_2)\n",
    "print(\"\\n生成的电力消耗 (示例 2 - 夏季下午):\")\n",
    "for zone, value in generated_power_2.items():\n",
    "    print(f\"  {zone}: {value:.2f}\")\n",
    "\n",
    "# 示例输入数据 3 (寒冷夜晚)\n",
    "example_input_data_3 = {\n",
    "    'Datetime': '2017-01-20 03:00:00',  # 冬季夜晚\n",
    "    'Temperature': 5.0,\n",
    "    'Humidity': 85.0,\n",
    "    'WindSpeed': 0.1,\n",
    "    'GeneralDiffuseFlows': 0.01,\n",
    "    'DiffuseFlows': 0.01\n",
    "}\n",
    "generated_power_3 = generate_power_consumption(example_input_data_3)\n",
    "print(\"\\n生成的电力消耗 (示例 3 - 寒冷夜晚):\")\n",
    "for zone, value in generated_power_3.items():\n",
    "    print(f\"  {zone}: {value:.2f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f104d474868d4156",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 示例输入数据 (Any data from df)\n",
    "example_input_data_3 = df.iloc[1, :6].to_dict()\n",
    "generated_power_3 = generate_power_consumption(example_input_data_3)\n",
    "print(\"\\n生成的电力消耗 (寒冷夜晚):\")\n",
    "for zone, value in generated_power_3.items():\n",
    "    print(f\"  {zone}: {value:.2f}\")\n",
    "\n",
    "df.iloc[1, 6:-3]  # ground truth"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d68efbc0d053685b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- 生成前2000行数据的预测并添加到DataFrame ---\n",
    "\n",
    "# 确保 df 已经加载并且是原始未缩放的数据\n",
    "# (如果您之前修改了df，可能需要重新加载或确保它包含原始值)\n",
    "# 例如: df = pd.read_csv(\"./data/powerconsumption.csv\")\n",
    "# df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "# 确定要处理的行数\n",
    "num_rows_to_predict = 5000\n",
    "\n",
    "# 准备存储预测结果的列表\n",
    "predictions_zone1 = []\n",
    "predictions_zone2 = []\n",
    "predictions_zone3 = []\n",
    "\n",
    "# 定义输入 generate_power_consumption 函数所需的列\n",
    "# 'Datetime' 必须包含在输入中以提取时间特征\n",
    "input_cols_for_generation = [\n",
    "    'Datetime', 'Temperature', 'Humidity', 'WindSpeed',\n",
    "    'GeneralDiffuseFlows', 'DiffuseFlows'\n",
    "]\n",
    "\n",
    "print(f\"正在为 df 的前 {num_rows_to_predict} 行生成预测...\")\n",
    "\n",
    "# 遍历 df 的前 num_rows_to_predict 行\n",
    "# 使用 tqdm 包装，提供进度条\n",
    "for i in tqdm(range(num_rows_to_predict), desc=\"生成预测\"):\n",
    "    # 从当前行提取输入数据，转换为字典\n",
    "    current_input_data = df.iloc[i][input_cols_for_generation].to_dict()\n",
    "\n",
    "    # 使用 generate_power_consumption 函数获取预测\n",
    "    generated_power = generate_power_consumption(current_input_data)\n",
    "\n",
    "    # 将预测结果添加到相应的列表中\n",
    "    predictions_zone1.append(generated_power['PowerConsumption_Zone1'])\n",
    "    predictions_zone2.append(generated_power['PowerConsumption_Zone2'])\n",
    "    predictions_zone3.append(generated_power['PowerConsumption_Zone3'])\n",
    "\n",
    "# 将预测结果作为新列添加到 df\n",
    "# 注意：这些新列将只包含前 num_rows_to_predict 行的数据，其余为 NaN\n",
    "df.loc[:num_rows_to_predict - 1, 'PowerConsumption_Zone1_Predict'] = predictions_zone1\n",
    "df.loc[:num_rows_to_predict - 1, 'PowerConsumption_Zone2_Predict'] = predictions_zone2\n",
    "df.loc[:num_rows_to_predict - 1, 'PowerConsumption_Zone3_Predict'] = predictions_zone3\n",
    "\n",
    "print(f\"成功将预测结果添加到 df 中，并创建了新的预测列。\")\n",
    "\n",
    "# 打印更新后的 df 的头部和新的预测列信息，以供检查\n",
    "print(\"\\n更新后的 df (前5行) 及新预测列:\")\n",
    "print(df[['Datetime'] + target_features + [col for col in df.columns if 'Predict' in col]].head())\n",
    "\n",
    "# 可以选择进一步打印一些特定行的对比\n",
    "print(f\"\\n第1行（索引为0）的实际与预测对比:\")\n",
    "print(\n",
    "    f\"实际 Zone1: {df.loc[0, 'PowerConsumption_Zone1']:.2f}, 预测 Zone1: {df.loc[0, 'PowerConsumption_Zone1_Predict']:.2f}\")\n",
    "print(\n",
    "    f\"实际 Zone2: {df.loc[0, 'PowerConsumption_Zone2']:.2f}, 预测 Zone2: {df.loc[0, 'PowerConsumption_Zone2_Predict']:.2f}\")\n",
    "print(\n",
    "    f\"实际 Zone3: {df.loc[0, 'PowerConsumption_Zone3']:.2f}, 预测 Zone3: {df.loc[0, 'PowerConsumption_Zone3_Predict']:.2f}\")\n",
    "\n",
    "print(f\"\\n第1000行（索引为999）的实际与预测对比:\")\n",
    "print(\n",
    "    f\"实际 Zone1: {df.loc[999, 'PowerConsumption_Zone1']:.2f}, 预测 Zone1: {df.loc[999, 'PowerConsumption_Zone1_Predict']:.2f}\")\n",
    "print(\n",
    "    f\"实际 Zone2: {df.loc[999, 'PowerConsumption_Zone2']:.2f}, 预测 Zone2: {df.loc[999, 'PowerConsumption_Zone2_Predict']:.2f}\")\n",
    "print(\n",
    "    f\"实际 Zone3: {df.loc[999, 'PowerConsumption_Zone3']:.2f}, 预测 Zone3: {df.loc[999, 'PowerConsumption_Zone3_Predict']:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5ca5dfd35c0d45c0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df[['Datetime', 'PowerConsumption_Zone1',\n",
    "#     'PowerConsumption_Zone2', 'PowerConsumption_Zone3', 'PowerConsumption_Zone1_Predict',\n",
    "#     'PowerConsumption_Zone2_Predict', 'PowerConsumption_Zone3_Predict']].iloc[:2000][::10].plot(x='Datetime',\n",
    "#                                                                                                 figsize=(18, 5))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "db8751847765e80c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 采样（每隔10个取1个，前2000个）\n",
    "df_sample = df.iloc[:2000]\n",
    "\n",
    "# 创建子图\n",
    "fig, axs = plt.subplots(3, 1, figsize=(18, 12), sharex=True)\n",
    "\n",
    "# 区域1\n",
    "axs[0].plot(df_sample['Datetime'], df_sample['PowerConsumption_Zone1'], label='Zone1 Real')\n",
    "axs[0].plot(df_sample['Datetime'], df_sample['PowerConsumption_Zone1_Predict'], label='Zone1 Predict')\n",
    "axs[0].set_title('Zone 1 Power Consumption')\n",
    "axs[0].legend()\n",
    "\n",
    "# 区域2\n",
    "axs[1].plot(df_sample['Datetime'], df_sample['PowerConsumption_Zone2'], label='Zone2 Real')\n",
    "axs[1].plot(df_sample['Datetime'], df_sample['PowerConsumption_Zone2_Predict'], label='Zone2 Predict')\n",
    "axs[1].set_title('Zone 2 Power Consumption')\n",
    "axs[1].legend()\n",
    "\n",
    "# 区域3\n",
    "axs[2].plot(df_sample['Datetime'], df_sample['PowerConsumption_Zone3'], label='Zone3 Real')\n",
    "axs[2].plot(df_sample['Datetime'], df_sample['PowerConsumption_Zone3_Predict'], label='Zone3 Predict')\n",
    "axs[2].set_title('Zone 3 Power Consumption')\n",
    "axs[2].legend()\n",
    "\n",
    "# 总体设置\n",
    "plt.xlabel('Datetime')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7d73bb171256881a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html energy_CVAE4.ipynb \n",
    "# !jupyter nbconvert --to markdown energy_CVAE2.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "75ef091fc04b7e72",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
